{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label</th>\n",
       "      <th>label_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Masuk Radar Pilwalkot Medan, Menantu Jokowi Be...</td>\n",
       "      <td>non-clickbait</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malaysia Sudutkan RI: Isu Kabut Asap hingga In...</td>\n",
       "      <td>non-clickbait</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Viral! Driver Ojol di Bekasi Antar Pesanan Mak...</td>\n",
       "      <td>clickbait</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kemensos Salurkan Rp 7,3 M bagi Korban Kerusuh...</td>\n",
       "      <td>non-clickbait</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Terkait Mayat Bayi Mengenaskan di Tangerang, S...</td>\n",
       "      <td>non-clickbait</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>Tolak RUU Pertanahan, Ribuan Petani Siap Gelar...</td>\n",
       "      <td>non-clickbait</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>Ada Niat Tambah Momongan Tanpa Ikut Program Ha...</td>\n",
       "      <td>clickbait</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>Beredar Isu Internet Papua Diblokir Lagi, Telk...</td>\n",
       "      <td>non-clickbait</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>TXT Akan Segera Comeback, Soobin Akui Gatal I...</td>\n",
       "      <td>clickbait</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>Emmy Awards 2019: Peter Dinklage Cetak Rekor B...</td>\n",
       "      <td>non-clickbait</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title          label  \\\n",
       "0      Masuk Radar Pilwalkot Medan, Menantu Jokowi Be...  non-clickbait   \n",
       "1      Malaysia Sudutkan RI: Isu Kabut Asap hingga In...  non-clickbait   \n",
       "2      Viral! Driver Ojol di Bekasi Antar Pesanan Mak...      clickbait   \n",
       "3      Kemensos Salurkan Rp 7,3 M bagi Korban Kerusuh...  non-clickbait   \n",
       "4      Terkait Mayat Bayi Mengenaskan di Tangerang, S...  non-clickbait   \n",
       "...                                                  ...            ...   \n",
       "14995  Tolak RUU Pertanahan, Ribuan Petani Siap Gelar...  non-clickbait   \n",
       "14996  Ada Niat Tambah Momongan Tanpa Ikut Program Ha...      clickbait   \n",
       "14997  Beredar Isu Internet Papua Diblokir Lagi, Telk...  non-clickbait   \n",
       "14998   TXT Akan Segera Comeback, Soobin Akui Gatal I...      clickbait   \n",
       "14999  Emmy Awards 2019: Peter Dinklage Cetak Rekor B...  non-clickbait   \n",
       "\n",
       "       label_score  \n",
       "0                0  \n",
       "1                0  \n",
       "2                1  \n",
       "3                0  \n",
       "4                0  \n",
       "...            ...  \n",
       "14995            0  \n",
       "14996            1  \n",
       "14997            0  \n",
       "14998            1  \n",
       "14999            0  \n",
       "\n",
       "[15000 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILE_PATH = 'annotated/combined/csv/main.csv'\n",
    "data = pd.read_csv(FILE_PATH)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  (12000,) (12000,) \n",
      "Test:  (3000,) (3000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train, Y_test = train_test_split(data['title'], data['label_score'], test_size=0.2, random_state=30)\n",
    "print(\"Train: \", X_train.shape, Y_train.shape, \"\\nTest: \", X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kelas non-clickbait training:  57.775 %\n",
      "Kelas clickbait training:  42.225 %\n"
     ]
    }
   ],
   "source": [
    "# Cek distribusi kelas training\n",
    "y_train_non = Y_train == 0\n",
    "y_train_bait = Y_train == 1\n",
    "print(\"Kelas non-clickbait training: \", (y_train_non.sum()/len(Y_train))*100, \"%\")\n",
    "print(\"Kelas clickbait training: \", (y_train_bait.sum()/len(Y_train))*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kelas non-clickbait testing:  59.233333333333334 %\n",
      "Kelas clickbait testing:  40.766666666666666 %\n"
     ]
    }
   ],
   "source": [
    "# Cek distribusi kelas latih\n",
    "y_test_non = Y_test == 0\n",
    "y_test_bait = Y_test == 1\n",
    "print(\"Kelas non-clickbait testing: \", (y_test_non.sum()/len(Y_test))*100, \"%\")\n",
    "print(\"Kelas clickbait testing: \", (y_test_bait.sum()/len(Y_test))*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<12000x88966 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 217777 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(\"TFIDF Vectorizer……\")\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer= TfidfVectorizer(ngram_range = (1,2),\n",
    "                    sublinear_tf = True)\n",
    "tf_x_train = vectorizer.fit_transform(X_train)\n",
    "tf_x_test = vectorizer.transform(X_test)\n",
    "tf_x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kebingungan ganda', 'kebingungan giampaolo', 'kebo', 'kebo tidak', 'kebobolan', 'kebobolan di', 'kebobolan tiga', 'kebocaran', 'kebocaran data', 'kebocoran', 'kebocoran klep', 'kebocoran stok', 'kebohongan', 'kebohongan dan', 'kebohongan pinokio', 'kebon', 'kebon jeruk', 'kebon sirih', 'kebotakan', 'kebtke', 'kebtke gelar', 'kebudayaan', 'kebudayaan nasional', 'kebugaran', 'kebumen', 'kebumen 16', 'kebumen aparat', 'kebumen hal', 'kebumen minta', 'kebumen versi', 'kebun', 'kebun lada', 'kebun raya', 'kebun tebu', 'kebut', 'kebut pembangunan', 'kebut pengesahan', 'kebut persiapan', 'kebutaan', 'kebutaan ngaku', 'kebutuhan', 'kebutuhan hidup', 'kebutuhan keluarga', 'kebutuhan komersial', 'kebutuhan tle', 'kebutuhan warga', 'kebutuhan zat', 'kecam', 'kecam balik', 'kecam keras', 'kecam ketua', 'kecam pemuda', 'kecam rencana', 'kecam serangan', 'kecamatan', 'kecamatan di', 'kecamatan pinolosian', 'kecanduan', 'kecanduan game', 'kecanduan gawai', 'kecanduan kopi', 'kecanduan main', 'kecanduan manicure', 'kecanduan memandang', 'kecanduan pubg', 'kecanduan seks', 'kecanggihannya', 'kecantikan', 'kecantikan baekhyun', 'kecantikan dan', 'kecantikan dari', 'kecantikan favoritnya', 'kecantikan hingga', 'kecantikan internasional', 'kecantikan jang', 'kecantikan kulit', 'kecantikan lisa', 'kecantikan park', 'kecantikan perempuan', 'kecantikan tradisional', 'kecantikan tzuyu', 'kecantikan veronica', 'kecantikan wajah', 'kecantikannya', 'kecantikannya di', 'kecantikannya sukses', 'kecap', 'kecap dan', 'kece', 'kece camila', 'kece dari', 'kece kibas', 'kece serba', 'kecelakaan', 'kecelakaan beruntun', 'kecelakaan bus', 'kecelakaan cipularang', 'kecelakaan di', 'kecelakaan dul', 'kecelakaan hingga']\n",
      "Vocabulary length: 88966\n"
     ]
    }
   ],
   "source": [
    "vocab = vectorizer.get_feature_names()\n",
    "print(vocab[39900:40000])\n",
    "print(\"Vocabulary length:\", len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klasifikasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ari\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:30:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.93      0.81      1777\n",
      "           1       0.82      0.48      0.60      1223\n",
      "\n",
      "    accuracy                           0.74      3000\n",
      "   macro avg       0.77      0.70      0.71      3000\n",
      "weighted avg       0.76      0.74      0.73      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_model=XGBClassifier()\n",
    "xgb_model.fit(tf_x_train,Y_train)\n",
    "xgb_pred=xgb_model.predict(tf_x_test)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, xgb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.90      0.82      1777\n",
      "           1       0.79      0.58      0.67      1223\n",
      "\n",
      "    accuracy                           0.77      3000\n",
      "   macro avg       0.78      0.74      0.75      3000\n",
      "weighted avg       0.77      0.77      0.76      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbm = LGBMClassifier()\n",
    "lgbm.fit(tf_x_train,Y_train)\n",
    "lgbm_pred=lgbm.predict(tf_x_test)\n",
    "print(classification_report(Y_test, lgbm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.90      0.83      1777\n",
      "           1       0.81      0.59      0.68      1223\n",
      "\n",
      "    accuracy                           0.77      3000\n",
      "   macro avg       0.78      0.74      0.75      3000\n",
      "weighted avg       0.78      0.77      0.77      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# importing random forest classifier from assemble module\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = 100) \n",
    " \n",
    "# Training the model on the training dataset\n",
    "# fit function is used to train the model using the training sets as parameters\n",
    "clf.fit(tf_x_train,Y_train)\n",
    " \n",
    "# performing predictions on the test dataset\n",
    "y_pred = clf.predict(tf_x_test)\n",
    "\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
